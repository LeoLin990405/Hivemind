#!/usr/bin/env python3
"""
Context Saver - System 1: Instant Context Archiving

Automatically saves session context to DATABASE when /clear or /compact
is executed. This is the "fast, automatic" part of the dual-system memory.

v2.0: æ”¹ä¸ºä¿å­˜åˆ°æ•°æ®åº“ï¼Œä¸å†ä½¿ç”¨ Markdown æ–‡ä»¶
"""

import json
import os
import re
import sqlite3
import sys
import uuid
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional

# Add parent directory to path for imports
sys.path.insert(0, str(Path(__file__).parent.parent))

from memory.jsonl_parser import ClaudeJsonlParser, SessionData, Message, ToolCall


class ContextSaver:
    """System 1: Instant context saver that archives sessions to DATABASE.

    v2.0: æ‰€æœ‰æ•°æ®ä¿å­˜åˆ° SQLite æ•°æ®åº“ï¼Œä¸å†ç”Ÿæˆ Markdown æ–‡ä»¶
    """

    # Database path
    DB_PATH = Path.home() / ".ccb" / "ccb_memory.db"

    def __init__(self, archive_dir: Optional[Path] = None, db_path: Optional[Path] = None):
        # Keep archive_dir for backward compatibility, but we use database now
        self.archive_dir = archive_dir or Path.home() / ".ccb" / "context_archive"
        self.archive_dir.mkdir(parents=True, exist_ok=True)
        self.db_path = db_path or self.DB_PATH
        self.parser = ClaudeJsonlParser()

        # Ensure database tables exist
        self._init_db()

    def _init_db(self):
        """Ensure session archive tables exist."""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        # Session archives table (System 1 output)
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS session_archives (
                archive_id TEXT PRIMARY KEY,
                session_id TEXT NOT NULL,
                user_id TEXT DEFAULT 'default',
                project_path TEXT,
                git_branch TEXT,
                model TEXT,
                start_time TEXT,
                end_time TEXT,
                duration_minutes INTEGER,
                message_count INTEGER DEFAULT 0,
                tool_call_count INTEGER DEFAULT 0,
                task_summary TEXT,
                key_messages TEXT,  -- JSON array
                tool_usage TEXT,    -- JSON object
                file_changes TEXT,  -- JSON array
                learnings TEXT,     -- JSON array
                metadata TEXT,      -- JSON object
                created_at TEXT DEFAULT CURRENT_TIMESTAMP,
                UNIQUE(session_id)
            )
        """)

        # Index for efficient queries
        cursor.execute("""
            CREATE INDEX IF NOT EXISTS idx_session_archives_created
            ON session_archives(created_at DESC)
        """)

        cursor.execute("""
            CREATE INDEX IF NOT EXISTS idx_session_archives_project
            ON session_archives(project_path)
        """)

        conn.commit()
        conn.close()

    def save_session(self, session_path: Path, force: bool = False) -> Optional[str]:
        """
        Save a session to DATABASE.

        Args:
            session_path: Path to the session.jsonl file
            force: If True, save even if session seems trivial

        Returns:
            archive_id if saved successfully, or None if skipped
        """
        if not session_path.exists():
            print(f"Session file not found: {session_path}", file=sys.stderr)
            return None

        try:
            session = self.parser.parse(session_path)
        except Exception as e:
            print(f"Error parsing session: {e}", file=sys.stderr)
            return None

        # Skip trivial sessions (less than 2 meaningful messages)
        if not force and len(session.messages) < 2:
            return None

        # Save to database
        archive_id = self._save_to_database(session)
        return archive_id

    def _save_to_database(self, session: SessionData) -> str:
        """Save session data to SQLite database."""
        archive_id = str(uuid.uuid4())

        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        try:
            # Extract structured data
            task_summary = self._extract_task_summary(session)
            key_messages = self._extract_key_messages(session)
            tool_summary = self.parser.get_tool_summary(session.tool_calls)
            learnings = self._extract_learnings(session)
            duration = self.parser.get_session_duration(session)

            # Convert to JSON
            key_messages_json = json.dumps([
                {
                    'role': m.role,
                    'content': self._truncate_content(m.content, 1000),
                    'timestamp': m.timestamp
                }
                for m in key_messages
            ], ensure_ascii=False)

            file_changes_json = json.dumps([
                {'path': fc.file_path, 'action': fc.action}
                for fc in session.file_changes[:50]
            ], ensure_ascii=False)

            # Calculate duration in minutes
            duration_minutes = 0
            if duration:
                # Parse duration string like "45 åˆ†é’Ÿ" or "1 å°æ—¶ 30 åˆ†é’Ÿ"
                import re
                hours_match = re.search(r'(\d+)\s*å°æ—¶', duration)
                mins_match = re.search(r'(\d+)\s*åˆ†', duration)
                if hours_match:
                    duration_minutes += int(hours_match.group(1)) * 60
                if mins_match:
                    duration_minutes += int(mins_match.group(1))

            cursor.execute("""
                INSERT OR REPLACE INTO session_archives (
                    archive_id, session_id, user_id, project_path, git_branch, model,
                    start_time, end_time, duration_minutes, message_count, tool_call_count,
                    task_summary, key_messages, tool_usage, file_changes, learnings, metadata
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                archive_id,
                session.session_id,
                'default',
                session.project_path,
                session.git_branch,
                session.model,
                session.start_time,
                session.end_time,
                duration_minutes,
                len(session.messages),
                len(session.tool_calls),
                task_summary,
                key_messages_json,
                json.dumps(tool_summary, ensure_ascii=False),
                file_changes_json,
                json.dumps(learnings, ensure_ascii=False),
                json.dumps({
                    'file_count': len(session.file_changes),
                    'source_file': str(session.session_id)
                }, ensure_ascii=False)
            ))

            conn.commit()
            print(f"âœ“ Session archived to database: {archive_id[:8]}")
            return archive_id

        except Exception as e:
            print(f"Error saving to database: {e}", file=sys.stderr)
            conn.rollback()
            return None
        finally:
            conn.close()

    def get_recent_archives(self, hours: int = 24, limit: int = 50) -> List[Dict[str, Any]]:
        """Get recent session archives from database.

        Args:
            hours: How many hours back to look
            limit: Maximum number of archives to return

        Returns:
            List of archive dictionaries
        """
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        try:
            cursor.execute("""
                SELECT * FROM session_archives
                WHERE created_at >= datetime('now', ?)
                ORDER BY created_at DESC
                LIMIT ?
            """, (f'-{hours} hours', limit))

            columns = [desc[0] for desc in cursor.description]
            results = []
            for row in cursor.fetchall():
                result = dict(zip(columns, row))
                # Parse JSON fields
                for field in ['key_messages', 'tool_usage', 'file_changes', 'learnings', 'metadata']:
                    if result.get(field):
                        try:
                            result[field] = json.loads(result[field])
                        except json.JSONDecodeError:
                            pass
                results.append(result)

            return results
        finally:
            conn.close()

    def search_archives(self, query: str, limit: int = 20) -> List[Dict[str, Any]]:
        """Search session archives by task summary or project.

        Args:
            query: Search query
            limit: Maximum results

        Returns:
            List of matching archives
        """
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        try:
            cursor.execute("""
                SELECT * FROM session_archives
                WHERE task_summary LIKE ? OR project_path LIKE ?
                ORDER BY created_at DESC
                LIMIT ?
            """, (f'%{query}%', f'%{query}%', limit))

            columns = [desc[0] for desc in cursor.description]
            results = []
            for row in cursor.fetchall():
                result = dict(zip(columns, row))
                for field in ['key_messages', 'tool_usage', 'file_changes', 'learnings', 'metadata']:
                    if result.get(field):
                        try:
                            result[field] = json.loads(result[field])
                        except json.JSONDecodeError:
                            pass
                results.append(result)

            return results
        finally:
            conn.close()

    def get_archive_stats(self) -> Dict[str, Any]:
        """Get statistics about session archives.

        Returns:
            Statistics dictionary
        """
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        try:
            # Total archives
            cursor.execute("SELECT COUNT(*) FROM session_archives")
            total = cursor.fetchone()[0]

            # Recent archives (last 24h)
            cursor.execute("""
                SELECT COUNT(*) FROM session_archives
                WHERE created_at >= datetime('now', '-24 hours')
            """)
            recent_24h = cursor.fetchone()[0]

            # Recent archives (last 7d)
            cursor.execute("""
                SELECT COUNT(*) FROM session_archives
                WHERE created_at >= datetime('now', '-7 days')
            """)
            recent_7d = cursor.fetchone()[0]

            # Total messages
            cursor.execute("SELECT SUM(message_count) FROM session_archives")
            total_messages = cursor.fetchone()[0] or 0

            # Total tool calls
            cursor.execute("SELECT SUM(tool_call_count) FROM session_archives")
            total_tool_calls = cursor.fetchone()[0] or 0

            # Projects worked on
            cursor.execute("SELECT COUNT(DISTINCT project_path) FROM session_archives")
            unique_projects = cursor.fetchone()[0]

            return {
                'total_archives': total,
                'recent_24h': recent_24h,
                'recent_7d': recent_7d,
                'total_messages': total_messages,
                'total_tool_calls': total_tool_calls,
                'unique_projects': unique_projects
            }
        except sqlite3.OperationalError:
            return {'error': 'session_archives table not found'}
        finally:
            conn.close()

    # Keep the original markdown generation for backward compatibility
    def _generate_markdown(self, session: SessionData) -> str:
        """Generate Markdown content from parsed session data."""
        lines = []

        # Header
        lines.append(f"# Session: {session.session_id}")
        lines.append("")

        # Metadata
        lines.append("## Metadata")
        lines.append(f"- **é¡¹ç›®è·¯å¾„**: `{session.project_path}`")
        if session.start_time:
            start_str = self._format_timestamp(session.start_time)
            end_str = self._format_timestamp(session.end_time) if session.end_time else "ongoing"
            lines.append(f"- **æ—¶é—´**: {start_str} ~ {end_str}")

        duration = self.parser.get_session_duration(session)
        if duration:
            lines.append(f"- **æ—¶é•¿**: {duration}")

        lines.append(f"- **æ¨¡åž‹**: {session.model or 'unknown'}")

        if session.git_branch and session.git_branch != 'HEAD':
            lines.append(f"- **Git åˆ†æ”¯**: {session.git_branch}")

        lines.append("")

        # Task Summary
        task_summary = self._extract_task_summary(session)
        if task_summary:
            lines.append("## ä»»åŠ¡æ‘˜è¦")
            lines.append(task_summary)
            lines.append("")

        # Key Conversations
        key_messages = self._extract_key_messages(session)
        if key_messages:
            lines.append("## å…³é”®å¯¹è¯")
            lines.append("")
            for msg in key_messages:
                time_str = self._format_time_short(msg.timestamp)
                role_cn = "ç”¨æˆ·" if msg.role == "user" else "Claude"
                lines.append(f"### {role_cn} {time_str}")

                # Format content as blockquote for user, normal for assistant
                if msg.role == "user":
                    content = self._truncate_content(msg.content, 500)
                    lines.append(f"> {content.replace(chr(10), chr(10) + '> ')}")
                else:
                    content = self._truncate_content(msg.content, 1000)
                    lines.append(content)

                lines.append("")

        # Tool Usage Summary
        tool_summary = self.parser.get_tool_summary(session.tool_calls)
        if tool_summary:
            lines.append("## å·¥å…·è°ƒç”¨")
            for tool, count in sorted(tool_summary.items(), key=lambda x: -x[1]):
                lines.append(f"- **{tool}**: {count}æ¬¡")
            lines.append("")

        # File Changes
        if session.file_changes:
            lines.append("## æ–‡ä»¶å˜æ›´")
            for fc in session.file_changes[:20]:  # Limit to top 20
                action_emoji = "ðŸ“" if fc.action == "modified" else "ðŸ“–"
                # Shorten path for readability
                short_path = self._shorten_path(fc.file_path)
                lines.append(f"- {action_emoji} `{short_path}` ({fc.action})")
            lines.append("")

        # Learnings (extracted from thinking or conversation patterns)
        learnings = self._extract_learnings(session)
        if learnings:
            lines.append("## å­¦åˆ°çš„çŸ¥è¯†")
            for learning in learnings:
                lines.append(f"- {learning}")
            lines.append("")

        # Footer
        lines.append("---")
        lines.append(f"*Archived by ccb-mem at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*")

        return "\n".join(lines)

    def _extract_task_summary(self, session: SessionData) -> str:
        """Extract a brief task summary from the first user message."""
        for msg in session.messages:
            if msg.role == "user" and len(msg.content) > 10:
                # Take first sentence or first 200 chars
                content = msg.content.strip()
                first_sentence = re.split(r'[ã€‚.!?ï¼ï¼Ÿ\n]', content)[0]
                if len(first_sentence) > 200:
                    first_sentence = first_sentence[:200] + "..."
                return first_sentence

        return ""

    def _extract_key_messages(self, session: SessionData, max_messages: int = 8) -> List[Message]:
        """Select the most important messages from the session."""
        key_messages = []

        # Always include first user message
        for msg in session.messages:
            if msg.role == "user":
                key_messages.append(msg)
                break

        # Include messages with substantial content
        for msg in session.messages:
            if msg in key_messages:
                continue

            # Skip very short messages
            if len(msg.content) < 50:
                continue

            # Prioritize user messages
            if msg.role == "user":
                key_messages.append(msg)
            # Include assistant messages with code blocks or structured content
            elif msg.role == "assistant":
                if '```' in msg.content or '##' in msg.content or len(msg.content) > 300:
                    key_messages.append(msg)

            if len(key_messages) >= max_messages:
                break

        # Sort by timestamp
        key_messages.sort(key=lambda m: m.timestamp)

        return key_messages

    def _extract_learnings(self, session: SessionData) -> List[str]:
        """Extract insights and learnings from the session."""
        learnings = []

        # Look for patterns in assistant messages
        learning_patterns = [
            r'(?:å‘çŽ°|åŽŸæ¥|æ³¨æ„åˆ°)[ï¼š:]\s*(.+?)(?:\n|$)',
            r'(?:è¿™æ˜¯å› ä¸º|åŽŸå› æ˜¯)[ï¼š:]\s*(.+?)(?:\n|$)',
            r'(?:å­¦åˆ°|æ˜Žç™½äº†)[ï¼š:]\s*(.+?)(?:\n|$)',
            r'(?:å…³é”®ç‚¹|è¦ç‚¹)[ï¼š:]\s*(.+?)(?:\n|$)',
        ]

        for msg in session.messages:
            if msg.role != "assistant":
                continue

            for pattern in learning_patterns:
                matches = re.findall(pattern, msg.content, re.IGNORECASE)
                for match in matches[:2]:  # Max 2 per pattern
                    if len(match) > 20 and len(match) < 200:
                        learnings.append(match.strip())

        # Deduplicate
        seen = set()
        unique = []
        for l in learnings:
            if l not in seen:
                seen.add(l)
                unique.append(l)

        return unique[:5]  # Max 5 learnings

    def _format_timestamp(self, ts: str) -> str:
        """Format ISO timestamp to readable format."""
        if not ts:
            return "unknown"
        try:
            dt = datetime.fromisoformat(ts.replace('Z', '+00:00'))
            return dt.strftime("%Y-%m-%d %H:%M")
        except Exception:
            return ts[:16] if len(ts) > 16 else ts

    def _format_time_short(self, ts: str) -> str:
        """Format timestamp to short time only."""
        if not ts:
            return ""
        try:
            dt = datetime.fromisoformat(ts.replace('Z', '+00:00'))
            return dt.strftime("%H:%M")
        except Exception:
            return ""

    def _truncate_content(self, content: str, max_len: int) -> str:
        """Truncate content to max length, preserving word boundaries."""
        if len(content) <= max_len:
            return content

        truncated = content[:max_len]
        # Try to break at word boundary
        last_space = truncated.rfind(' ')
        if last_space > max_len * 0.7:
            truncated = truncated[:last_space]

        return truncated + "..."

    def _shorten_path(self, path: str) -> str:
        """Shorten file path for display."""
        home = str(Path.home())
        if path.startswith(home):
            return "~" + path[len(home):]
        return path


def find_current_session() -> Optional[Path]:
    """Find the most recent Claude session file for the current directory."""
    claude_dir = Path.home() / ".claude" / "projects"

    if not claude_dir.exists():
        return None

    # Get all session files
    sessions = list(claude_dir.glob("**/*.jsonl"))

    if not sessions:
        return None

    # Find most recently modified
    sessions.sort(key=lambda p: p.stat().st_mtime, reverse=True)
    return sessions[0]


def main():
    """CLI entry point for context saver."""
    import argparse

    parser = argparse.ArgumentParser(
        description="Save Claude session context to Markdown archive"
    )
    parser.add_argument(
        "--session",
        type=Path,
        help="Path to session.jsonl file (default: auto-detect)"
    )
    parser.add_argument(
        "--output-dir",
        type=Path,
        help="Output directory (default: ~/.ccb/context_archive)"
    )
    parser.add_argument(
        "--force",
        action="store_true",
        help="Save even trivial sessions"
    )
    parser.add_argument(
        "--quiet",
        action="store_true",
        help="Suppress output"
    )

    args = parser.parse_args()

    # Determine session path
    session_path = args.session
    if not session_path:
        # Try to get from environment (set by hook)
        env_path = os.environ.get('CLAUDE_SESSION_PATH')
        if env_path:
            session_path = Path(env_path)
        else:
            session_path = find_current_session()

    if not session_path:
        if not args.quiet:
            print("No session file found", file=sys.stderr)
        sys.exit(1)

    # Create saver and save
    saver = ContextSaver(archive_dir=args.output_dir)
    result = saver.save_session(session_path, force=args.force)

    if result:
        if not args.quiet:
            print(f"âœ“ Saved context to: {result}")
        sys.exit(0)
    else:
        if not args.quiet:
            print("Session too short, skipped saving", file=sys.stderr)
        sys.exit(0)  # Not an error, just skipped


if __name__ == "__main__":
    main()
