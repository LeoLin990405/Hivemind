"""
CLI Execution Backend for CCB Gateway.

Executes AI CLI tools as subprocesses (Codex, Gemini CLI, etc.)
"""
from __future__ import annotations

import asyncio
import os
import re
import shutil
import subprocess
import time
import webbrowser
from typing import Optional, List, Tuple

from .base_backend import BaseBackend, BackendResult
from ..models import GatewayRequest
from ..gateway_config import ProviderConfig
from ..stream_output import StreamOutput, get_stream_manager


def estimate_tokens(text: str) -> int:
    """
    Estimate token count from text.

    Uses a simple heuristic: ~4 characters per token for English,
    ~1.5 characters per token for Chinese/CJK.
    """
    if not text:
        return 0

    # Count CJK characters (Chinese, Japanese, Korean)
    cjk_pattern = re.compile(r'[\u4e00-\u9fff\u3040-\u309f\u30a0-\u30ff\uac00-\ud7af]')
    cjk_chars = len(cjk_pattern.findall(text))

    # Non-CJK characters
    non_cjk_chars = len(text) - cjk_chars

    # Estimate: CJK ~1.5 chars/token, non-CJK ~4 chars/token
    cjk_tokens = cjk_chars / 1.5
    non_cjk_tokens = non_cjk_chars / 4

    return int(cjk_tokens + non_cjk_tokens)


def estimate_input_output_tokens(input_text: str, output_text: str) -> Tuple[int, int]:
    """
    Estimate input and output token counts.

    Returns:
        Tuple of (input_tokens, output_tokens)
    """
    return estimate_tokens(input_text), estimate_tokens(output_text)


# Patterns for detecting OAuth/auth URLs
AUTH_URL_PATTERNS = [
    r'https://accounts\.google\.com/o/oauth2[^\s\'"]+',
    r'https://[^\s\'"]*auth[^\s\'"]*code[^\s\'"]*',
    r'https://[^\s\'"]*authorize[^\s\'"]*',
]


def _should_auto_open_auth() -> bool:
    """Check if auto-open auth is enabled."""
    val = os.environ.get("CCB_AUTO_OPEN_AUTH", "1").lower()
    return val in ("1", "true", "yes", "on")


def _extract_auth_url(text: str) -> Optional[str]:
    """Extract OAuth/auth URL from text."""
    for pattern in AUTH_URL_PATTERNS:
        match = re.search(pattern, text)
        if match:
            return match.group(0)
    return None


def _open_auth_url(url: str) -> bool:
    """Open auth URL in browser."""
    try:
        # Try webbrowser module first
        webbrowser.open(url)
        return True
    except Exception:
        pass

    try:
        # Fallback to system open command (macOS)
        subprocess.run(["open", url], check=True, capture_output=True)
        return True
    except Exception:
        pass

    return False


def _open_auth_terminal(provider: str) -> bool:
    """Open a new terminal window for authentication."""
    # Different providers have different auth commands
    # Gemini uses interactive mode to trigger OAuth flow
    auth_commands = {
        "gemini": "gemini -i 'Please authenticate'",  # Interactive mode triggers OAuth
        "claude": "claude auth login",
        "codex": "codex auth login",
    }

    cmd = auth_commands.get(provider)
    if not cmd:
        return False

    try:
        # Try WezTerm first
        wezterm_path = shutil.which("wezterm")
        if wezterm_path:
            subprocess.Popen(
                [wezterm_path, "cli", "spawn", "--", "bash", "-c", f"{cmd}; echo 'Press Enter to close'; read"],
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL,
            )
            return True
    except Exception:
        pass

    try:
        # Fallback to macOS Terminal
        script = f'''
        tell application "Terminal"
            activate
            do script "{cmd}"
        end tell
        '''
        subprocess.run(["osascript", "-e", script], check=True, capture_output=True)
        return True
    except Exception:
        pass

    return False


class CLIBackend(BaseBackend):
    """
    CLI execution backend for command-line AI tools.

    Supports:
    - Codex CLI
    - Gemini CLI
    - OpenCode
    - iFlow
    - Kimi
    - Qwen
    - Any CLI tool that accepts input via stdin or arguments
    """

    def __init__(self, config: ProviderConfig):
        super().__init__(config)
        self._cli_path: Optional[str] = None

    async def _ensure_gemini_token(self) -> None:
        """Ensure Gemini OAuth token is valid, refresh if needed."""
        try:
            from ..gemini_auth import ensure_valid_token
            success, msg = ensure_valid_token()
            if not success:
                print(f"[CCB] Gemini token refresh warning: {msg}")
        except ImportError:
            pass  # gemini_auth module not available
        except Exception as e:
            print(f"[CCB] Gemini token check error: {e}")

    def _find_cli(self) -> Optional[str]:
        """Find the CLI executable."""
        if self._cli_path:
            return self._cli_path

        cmd = self.config.cli_command
        if not cmd:
            return None

        # Check if it's an absolute path
        if os.path.isabs(cmd) and os.path.isfile(cmd):
            self._cli_path = cmd
            return self._cli_path

        # Search in PATH first
        self._cli_path = shutil.which(cmd)
        if self._cli_path:
            return self._cli_path

        # Search in common user bin directories (may not be in PATH for background processes)
        home = os.path.expanduser("~")
        common_paths = [
            os.path.join(home, ".local", "bin"),
            os.path.join(home, ".npm-global", "bin"),
            os.path.join(home, "bin"),
            "/opt/homebrew/bin",
            "/usr/local/bin",
            os.path.join(home, ".qoder", "bin", "qodercli"),
        ]
        for path in common_paths:
            full_path = os.path.join(path, cmd)
            if os.path.isfile(full_path) and os.access(full_path, os.X_OK):
                self._cli_path = full_path
                return self._cli_path

        return None

    def _build_command(self, message: str) -> List[str]:
        """Build the command line arguments."""
        cli = self._find_cli()
        if not cli:
            raise ValueError(f"CLI command not found: {self.config.cli_command}")

        cmd = [cli]

        # Add configured arguments
        if self.config.cli_args:
            cmd.extend(self.config.cli_args)

        # Add the message as the final argument
        # Most CLI tools accept the prompt as the last argument
        cmd.append(message)

        return cmd

    def _resolve_cwd(self) -> Optional[str]:
        """Resolve configured working directory for CLI execution."""
        if not self.config.cli_cwd:
            return None
        cwd = os.path.expanduser(os.path.expandvars(self.config.cli_cwd))
        return cwd or None

    async def execute(self, request: GatewayRequest) -> BackendResult:
        """Execute request via CLI subprocess with streaming output."""
        start_time = time.time()

        # Create stream output for real-time logging
        stream_manager = get_stream_manager()
        stream = stream_manager.create_stream(request.id, self.config.name)
        stream.status(f"Starting {self.config.name} CLI execution")

        cli = self._find_cli()
        if not cli:
            error_msg = f"CLI command not found: {self.config.cli_command}"
            stream.error(error_msg)
            stream.complete(error=error_msg)
            return BackendResult.fail(
                error_msg,
                latency_ms=(time.time() - start_time) * 1000,
            )

        try:
            # For Gemini, ensure OAuth token is valid before executing
            if self.config.name == "gemini":
                stream.status("Checking Gemini OAuth token...")
                await self._ensure_gemini_token()

            cmd = self._build_command(request.message)
            print(f"[DEBUG CLIBackend] Provider={self.config.name}, Full Command: {cmd}")
            stream.status(f"Executing: {' '.join(cmd[:2])}...")

            # Set up environment for non-interactive execution
            env = os.environ.copy()
            env["TERM"] = "dumb"
            env["NO_COLOR"] = "1"
            env["CI"] = "1"  # Many CLIs detect CI mode and disable interactivity
            cwd = self._resolve_cwd()
            if cwd and not os.path.isdir(cwd):
                stream.status(f"Configured cwd not found: {cwd}, using default")
                cwd = None

            # Try PTY mode first for CLIs that need terminal (like Gemini)
            # This allows us to capture auth URLs that are only shown in TTY mode
            # Enable by default for Gemini since it requires TTY
            use_pty = os.environ.get("CCB_CLI_USE_PTY", "0").lower() in ("1", "true", "yes")

            # For Gemini with -p flag, use regular subprocess (no TTY needed)
            # WezTerm mode is only for interactive Gemini sessions
            use_wezterm_for_gemini = os.environ.get("CCB_GEMINI_USE_WEZTERM", "0").lower() in ("1", "true", "yes")

            if self.config.name == "gemini" and use_wezterm_for_gemini:
                debug = os.environ.get("CCB_DEBUG", "0").lower() in ("1", "true", "yes")
                if debug:
                    print(f"[CCB] Using WezTerm for Gemini, cmd: {cmd}")
                stream.status("Using WezTerm mode for Gemini...")
                result = await self._execute_with_wezterm(cmd, request.timeout_s or self.config.timeout_s, cwd)
                if debug:
                    print(f"[CCB] WezTerm result: {result}")
                if result is not None:
                    stdout, stderr, returncode = result
                    latency_ms = (time.time() - start_time) * 1000
                    backend_result = self._process_output(stdout, stderr, returncode, latency_ms, request.message)
                    if backend_result.success:
                        if backend_result.thinking:
                            stream.thinking(backend_result.thinking)
                        stream.output(backend_result.response or "")
                        stream.complete(response=backend_result.response)
                    else:
                        stream.error(backend_result.error or "Unknown error")
                        stream.complete(error=backend_result.error)
                    return backend_result
                if debug:
                    print(f"[CCB] WezTerm returned None, falling back to subprocess")

            if use_pty:
                stream.status("Using PTY mode...")
                result = await self._execute_with_pty(cmd, env, request.timeout_s or self.config.timeout_s, cwd)
                if result is not None:
                    stdout, stderr, returncode = result
                    latency_ms = (time.time() - start_time) * 1000
                    backend_result = self._process_output(stdout, stderr, returncode, latency_ms, request.message)
                    if backend_result.success:
                        if backend_result.thinking:
                            stream.thinking(backend_result.thinking)
                        stream.output(backend_result.response or "")
                        stream.complete(response=backend_result.response)
                    else:
                        stream.error(backend_result.error or "Unknown error")
                        stream.complete(error=backend_result.error)
                    return backend_result

            # Fallback to regular subprocess with streaming
            stream.status("Starting subprocess...")
            result = await self._execute_with_streaming(cmd, env, request.timeout_s or self.config.timeout_s, stream, cwd)

            if result is not None:
                stdout, stderr, returncode = result
                latency_ms = (time.time() - start_time) * 1000
                backend_result = self._process_output(stdout, stderr, returncode, latency_ms, request.message)

                if backend_result.success:
                    if backend_result.thinking:
                        stream.thinking(backend_result.thinking)
                    stream.complete(response=backend_result.response)
                else:
                    stream.complete(error=backend_result.error)

                return backend_result

            # Fallback without streaming
            process = await asyncio.create_subprocess_exec(
                *cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE,
                stdin=asyncio.subprocess.DEVNULL,
                env=env,
                cwd=cwd,
            )

            try:
                stdout, stderr = await asyncio.wait_for(
                    process.communicate(),
                    timeout=request.timeout_s or self.config.timeout_s,
                )
            except asyncio.TimeoutError:
                process.kill()
                await process.wait()
                # On timeout, check if this provider needs auth
                latency_ms = (time.time() - start_time) * 1000
                provider_name = self.config.name
                error_msg = f"CLI command timed out after {request.timeout_s}s"
                stream.error(error_msg)
                if provider_name in ("gemini", "claude", "codex") and _should_auto_open_auth():
                    opened = _open_auth_terminal(provider_name)
                    if opened:
                        auth_error = f"CLI command timed out. This may be due to authentication. A terminal window has been opened for you to complete authentication for {provider_name}. Please retry after authenticating."
                        stream.complete(error=auth_error)
                        return BackendResult.fail(
                            auth_error,
                            latency_ms=latency_ms,
                            metadata={"auth_required": True, "auth_terminal_opened": True},
                        )
                stream.complete(error=error_msg)
                return BackendResult.fail(error_msg, latency_ms=latency_ms)

            latency_ms = (time.time() - start_time) * 1000
            backend_result = self._process_output(
                stdout.decode("utf-8", errors="replace"),
                stderr.decode("utf-8", errors="replace"),
                process.returncode,
                latency_ms,
                request.message,
            )

            if backend_result.success:
                if backend_result.thinking:
                    stream.thinking(backend_result.thinking)
                stream.output(backend_result.response or "")
                stream.complete(response=backend_result.response)
            else:
                stream.error(backend_result.error or "Unknown error")
                stream.complete(error=backend_result.error)

            return backend_result

        except Exception as e:
            error_msg = str(e)
            stream.error(error_msg)
            stream.complete(error=error_msg)
            return BackendResult.fail(
                error_msg,
                latency_ms=(time.time() - start_time) * 1000,
            )

    async def _execute_with_streaming(
        self, cmd: List[str], env: dict, timeout: float, stream: StreamOutput, cwd: Optional[str]
    ) -> Optional[tuple]:
        """Execute command with real-time streaming output."""
        try:
            process = await asyncio.create_subprocess_exec(
                *cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE,
                stdin=asyncio.subprocess.DEVNULL,
                env=env,
                cwd=cwd,
            )

            stdout_parts = []
            stderr_parts = []
            deadline = time.time() + timeout
            chunk_buffer = ""

            async def read_stream(stream_reader, parts, stream_type):
                nonlocal chunk_buffer
                while True:
                    try:
                        remaining = deadline - time.time()
                        if remaining <= 0:
                            break
                        chunk = await asyncio.wait_for(
                            stream_reader.read(1024),
                            timeout=min(5.0, remaining)
                        )
                        if not chunk:
                            break
                        decoded = chunk.decode("utf-8", errors="replace")
                        parts.append(decoded)

                        # Stream output chunks (dedupe rapid small chunks)
                        chunk_buffer += decoded
                        if len(chunk_buffer) > 100 or '\n' in chunk_buffer:
                            stream.chunk(chunk_buffer, source=stream_type)
                            chunk_buffer = ""

                    except asyncio.TimeoutError:
                        continue

            # Read both streams concurrently
            await asyncio.gather(
                read_stream(process.stdout, stdout_parts, "stdout"),
                read_stream(process.stderr, stderr_parts, "stderr"),
            )

            # Flush remaining buffer
            if chunk_buffer:
                stream.chunk(chunk_buffer, source="stdout")

            # Wait for process
            try:
                await asyncio.wait_for(process.wait(), timeout=5.0)
            except asyncio.TimeoutError:
                process.kill()
                await process.wait()

            return "".join(stdout_parts), "".join(stderr_parts), process.returncode or 0

        except Exception as e:
            stream.error(f"Streaming execution error: {e}")
            return None

    async def _execute_with_wezterm(
        self, cmd: List[str], timeout: float, cwd: Optional[str]
    ) -> Optional[tuple]:
        """Execute command in WezTerm pane and capture output.

        This is used for CLIs like Gemini that require a real TTY.
        """
        import uuid

        wezterm_path = shutil.which("wezterm")
        if not wezterm_path:
            return None

        # Create a temp file to capture output
        output_file = f"/tmp/ccb_wezterm_{uuid.uuid4().hex[:8]}.txt"
        debug = os.environ.get("CCB_DEBUG", "0").lower() in ("1", "true", "yes")

        try:
            # Build command that writes output to file
            cmd_str = " ".join(f'"{c}"' if " " in c else c for c in cmd)
            if cwd:
                wrapper_cmd = f'cd "{cwd}" && {cmd_str} > "{output_file}" 2>&1; echo "CCB_EXIT_CODE:$?" >> "{output_file}"'
            else:
                wrapper_cmd = f'{cmd_str} > "{output_file}" 2>&1; echo "CCB_EXIT_CODE:$?" >> "{output_file}"'

            if debug:
                print(f"[CCB WezTerm] Spawning: {wrapper_cmd}")

            # Spawn in WezTerm and wait
            spawn_result = subprocess.run(
                [wezterm_path, "cli", "spawn", "--", "bash", "-c", wrapper_cmd],
                capture_output=True,
                text=True,
                timeout=5,
            )

            if debug:
                print(f"[CCB WezTerm] Spawn result: {spawn_result.returncode}, stdout: {spawn_result.stdout}, stderr: {spawn_result.stderr}")

            if spawn_result.returncode != 0:
                return None

            # Get the pane ID from spawn output
            pane_id = spawn_result.stdout.strip()

            # Wait for command to complete by polling the output file
            deadline = time.time() + timeout
            while time.time() < deadline:
                await asyncio.sleep(0.5)

                # Check if output file exists and has exit code marker
                if os.path.exists(output_file):
                    try:
                        with open(output_file, "r") as f:
                            content = f.read()

                        if debug:
                            print(f"[CCB WezTerm] File content ({len(content)} chars): {content[:200]}...")

                        # Look for exit code marker (may not have newline before it)
                        import re
                        match = re.search(r"CCB_EXIT_CODE:(\d+)", content)
                        if match:
                            exit_code = int(match.group(1))
                            # Remove the exit code marker from output
                            output = re.sub(r"CCB_EXIT_CODE:\d+\s*$", "", content)
                            if debug:
                                print(f"[CCB WezTerm] Success! Exit code: {exit_code}")
                            return output.strip(), "", exit_code
                    except Exception as e:
                        if debug:
                            print(f"[CCB WezTerm] Error reading file: {e}")

            # Timeout - try to kill the pane
            if debug:
                print(f"[CCB WezTerm] Timeout, killing pane {pane_id}")
            try:
                subprocess.run(
                    [wezterm_path, "cli", "kill-pane", "--pane-id", pane_id],
                    capture_output=True,
                    timeout=2,
                )
            except Exception:
                pass

            return None

        finally:
            # Clean up temp file
            try:
                if os.path.exists(output_file):
                    os.remove(output_file)
            except Exception:
                pass

    async def _execute_with_pty(
        self, cmd: List[str], env: dict, timeout: float, cwd: Optional[str]
    ) -> Optional[tuple]:
        """Execute command with PTY to capture output from TTY-dependent CLIs."""
        import pty
        import select

        try:
            # Create PTY
            master_fd, slave_fd = pty.openpty()

            # Start process with PTY
            process = await asyncio.create_subprocess_exec(
                *cmd,
                stdout=slave_fd,
                stderr=slave_fd,
                stdin=asyncio.subprocess.DEVNULL,
                env=env,
                cwd=cwd,
            )

            os.close(slave_fd)

            # Read output with timeout
            output_parts = []
            deadline = time.time() + timeout

            loop = asyncio.get_event_loop()

            while time.time() < deadline:
                remaining = deadline - time.time()
                if remaining <= 0:
                    break

                # Use select to check if data is available
                try:
                    ready, _, _ = await asyncio.wait_for(
                        loop.run_in_executor(
                            None,
                            lambda: select.select([master_fd], [], [], min(1.0, remaining))
                        ),
                        timeout=min(2.0, remaining),
                    )
                except asyncio.TimeoutError:
                    continue

                if master_fd in ready:
                    try:
                        data = os.read(master_fd, 4096)
                        if not data:
                            break
                        output_parts.append(data.decode("utf-8", errors="replace"))
                    except OSError:
                        break

                # Check if process has finished
                if process.returncode is not None:
                    break

            os.close(master_fd)

            # Wait for process to finish
            try:
                await asyncio.wait_for(process.wait(), timeout=2.0)
            except asyncio.TimeoutError:
                process.kill()
                await process.wait()

            output = "".join(output_parts)
            # Debug: print captured output for troubleshooting
            if os.environ.get("CCB_DEBUG", "0").lower() in ("1", "true", "yes"):
                print(f"[CCB PTY] Captured output ({len(output)} chars): {output[:500]}")
            return output, "", process.returncode or 0

        except Exception as e:
            # PTY not available or failed, return None to use fallback
            return None

    def _process_output(
        self, stdout: str, stderr: str, returncode: int, latency_ms: float,
        input_text: str = ""
    ) -> BackendResult:
        """Process CLI output and check for auth URLs."""
        stdout = stdout.strip()
        stderr = stderr.strip()

        # Check for auth URL in output (stdout or stderr)
        combined_output = stdout + "\n" + stderr
        auth_url = _extract_auth_url(combined_output)
        if auth_url:
            if _should_auto_open_auth():
                opened = _open_auth_url(auth_url)
                auth_msg = f"Authentication required. {'Browser opened automatically.' if opened else 'Please open this URL:'}\n{auth_url}"
            else:
                auth_msg = f"Authentication required. Please open this URL:\n{auth_url}"
            return BackendResult.fail(
                auth_msg,
                latency_ms=latency_ms,
                metadata={"auth_required": True, "auth_url": auth_url},
            )

        # Check for auth-related errors (timeout with no output often means auth needed)
        auth_indicators = [
            "authorization",
            "authenticate",
            "login required",
            "not logged in",
            "credentials",
            "token expired",
            "unauthorized",
        ]
        if returncode != 0 or (not stdout and not stderr):
            combined_lower = combined_output.lower()
            needs_auth = any(ind in combined_lower for ind in auth_indicators)

            # If no output and timeout, likely auth issue for Gemini
            if not stdout and not stderr and self.config.name == "gemini":
                needs_auth = True

            if needs_auth and _should_auto_open_auth():
                opened = _open_auth_terminal(self.config.name)
                if opened:
                    return BackendResult.fail(
                        f"Authentication required for {self.config.name}. A terminal window has been opened for you to complete authentication. Please retry after authenticating.",
                        latency_ms=latency_ms,
                        metadata={"auth_required": True, "auth_terminal_opened": True},
                    )

        # Try to extract just the response if there's metadata
        response_text, thinking = self._clean_output(stdout)
        raw_output = stdout  # Store raw output for monitoring

        # If we have valid output, consider it a success even if exit code is non-zero
        # Many CLI tools return non-zero exit codes for various reasons but still produce valid output
        if response_text:
            # Estimate tokens for CLI backends
            input_tokens, output_tokens = estimate_input_output_tokens(input_text, response_text)
            total_tokens = input_tokens + output_tokens

            return BackendResult.ok(
                response=response_text,
                latency_ms=latency_ms,
                tokens_used=total_tokens,
                metadata={
                    "exit_code": returncode,
                    "input_tokens": input_tokens,
                    "output_tokens": output_tokens,
                    "tokens_estimated": True,
                },
                thinking=thinking,
                raw_output=raw_output,
            )

        # No valid output - check return code for error
        if returncode != 0:
            def _snip(text: str, limit: int = 1200) -> str:
                text = text.strip()
                if len(text) <= limit:
                    return text
                return text[-limit:]

            detail_parts = []
            if stderr:
                detail_parts.append(f"stderr:\n{_snip(stderr)}")
            if stdout and (not stderr or _snip(stdout) != _snip(stderr)):
                detail_parts.append(f"stdout:\n{_snip(stdout)}")

            detail = "\n\n".join(p for p in detail_parts if p).strip()
            if detail:
                error_msg = f"CLI exited with code {returncode}\n{detail}"
            else:
                error_msg = f"CLI exited with code {returncode}"
            return BackendResult.fail(error_msg, latency_ms=latency_ms)

        # Empty output but success exit code
        input_tokens = estimate_tokens(input_text)
        return BackendResult.ok(
            response="",
            latency_ms=latency_ms,
            tokens_used=input_tokens,
            metadata={
                "exit_code": returncode,
                "input_tokens": input_tokens,
                "output_tokens": 0,
                "tokens_estimated": True,
            },
            raw_output=raw_output,
        )

    def _extract_thinking(self, text: str) -> tuple:
        """Extract thinking/reasoning chain from text.

        Returns:
            Tuple of (cleaned_text, thinking_content)
        """
        import re

        thinking_parts = []
        cleaned_text = text

        # Pattern 1: <thinking>...</thinking> tags (Claude style)
        thinking_pattern = re.compile(r'<thinking>(.*?)</thinking>', re.DOTALL | re.IGNORECASE)
        matches = thinking_pattern.findall(text)
        if matches:
            thinking_parts.extend(matches)
            cleaned_text = thinking_pattern.sub('', cleaned_text)

        # Pattern 2: <antThinking>...</antThinking> tags
        ant_pattern = re.compile(r'<antThinking>(.*?)</antThinking>', re.DOTALL | re.IGNORECASE)
        matches = ant_pattern.findall(cleaned_text)
        if matches:
            thinking_parts.extend(matches)
            cleaned_text = ant_pattern.sub('', cleaned_text)

        # Pattern 3: [Thinking] ... [/Thinking] or similar markers
        bracket_pattern = re.compile(r'\[Thinking\](.*?)\[/Thinking\]', re.DOTALL | re.IGNORECASE)
        matches = bracket_pattern.findall(cleaned_text)
        if matches:
            thinking_parts.extend(matches)
            cleaned_text = bracket_pattern.sub('', cleaned_text)

        # Pattern 4: Lines starting with "Thinking:" or "Reasoning:"
        lines = cleaned_text.split('\n')
        new_lines = []
        in_thinking = False
        thinking_buffer = []

        for line in lines:
            lower_line = line.lower().strip()
            if lower_line.startswith('thinking:') or lower_line.startswith('reasoning:'):
                in_thinking = True
                thinking_buffer.append(line)
            elif in_thinking and (line.startswith('  ') or line.startswith('\t') or not line.strip()):
                thinking_buffer.append(line)
            else:
                if thinking_buffer:
                    thinking_parts.append('\n'.join(thinking_buffer))
                    thinking_buffer = []
                in_thinking = False
                new_lines.append(line)

        if thinking_buffer:
            thinking_parts.append('\n'.join(thinking_buffer))

        cleaned_text = '\n'.join(new_lines)
        thinking = '\n\n---\n\n'.join(thinking_parts) if thinking_parts else None

        return cleaned_text.strip(), thinking

    def _clean_output(self, output: str) -> tuple:
        """Clean CLI output to extract just the response.

        Returns:
            Tuple of (cleaned_response, thinking_content)
        """
        # Qoder special handling: output is usually clean, just trim status lines
        if self.config.name == "qoder":
            cleaned_lines = []
            for line in output.strip().split("\n"):
                # Skip Qoder-specific status lines
                if any(skip in line.lower() for skip in [
                    "loading",
                    "context engine",
                    "analyzing",
                    "mcp:",
                    "job id:",
                ]):
                    continue
                cleaned_lines.append(line)
            return "\n".join(cleaned_lines).strip(), None

        # Check if output is JSONL (Codex --json mode or OpenCode --format json)
        lines = output.strip().split("\n")

        # Try to parse as JSONL and extract response text
        import json
        text_parts = []
        thinking_parts = []

        for line in lines:
            line = line.strip()
            if not line:
                continue
            try:
                data = json.loads(line)
                # Only process dict objects
                if not isinstance(data, dict):
                    continue
                # Codex JSON format: look for agent_message and thinking
                if data.get("type") == "item.completed":
                    item = data.get("item", {})
                    if item.get("type") == "agent_message":
                        text_parts.append(item.get("text", ""))
                    elif item.get("type") == "thinking":
                        thinking_parts.append(item.get("text", ""))
                # Codex thinking events
                if data.get("type") == "thinking":
                    thinking_parts.append(data.get("text", ""))
                # OpenCode JSON format: look for text type
                if data.get("type") == "text":
                    part = data.get("part", {})
                    if part.get("type") == "text" and part.get("text"):
                        text_parts.append(part.get("text"))
                    elif part.get("type") == "thinking" and part.get("text"):
                        thinking_parts.append(part.get("text"))
            except json.JSONDecodeError:
                continue

        # Return collected text parts from JSON format
        if text_parts:
            response = "\n".join(text_parts)
            thinking = "\n\n---\n\n".join(thinking_parts) if thinking_parts else None
            return response, thinking

        # Try to find a JSON object with "response" field (Gemini CLI format)
        # Search for all JSON objects and find one with "response" key
        import re
        # Find all potential JSON object starts
        json_objects = []
        i = 0
        while i < len(output):
            if output[i] == "{":
                brace_count = 0
                start = i
                for j in range(i, len(output)):
                    if output[j] == "{":
                        brace_count += 1
                    elif output[j] == "}":
                        brace_count -= 1
                        if brace_count == 0:
                            json_objects.append(output[start:j+1])
                            i = j
                            break
            i += 1

        # Look for JSON object with "response" field (not "error" field)
        for json_str in json_objects:
            try:
                data = json.loads(json_str)
                if isinstance(data, dict) and "response" in data and "error" not in data:
                    return data["response"], None
            except (json.JSONDecodeError, ValueError):
                continue

        # Fallback: clean regular output and extract thinking
        cleaned_text, thinking = self._extract_thinking(output)

        cleaned_lines = []
        for line in cleaned_text.split("\n"):
            # Skip common status lines
            if any(skip in line.lower() for skip in [
                "loading",
                "initializing",
                "connecting",
                "thinking...",
                "processing...",
                "mcp:",
                "--------",
                "workdir:",
                "model:",
                "provider:",
                "approval:",
                "sandbox:",
                "reasoning effort:",
                "reasoning summaries:",
                "session id:",
                "tokens used",
                "loaded cached credentials",
                "hook registry initialized",
                "credentials loaded",
            ]):
                continue
            # Skip lines that look like metadata
            if line.startswith("OpenAI") or line.startswith("user"):
                continue
            cleaned_lines.append(line)

        return "\n".join(cleaned_lines).strip(), thinking

    async def health_check(self) -> bool:
        """Check if the CLI is available.

        For CLIs that have slow startup (like Gemini with OAuth),
        we just check if the binary exists and is executable.
        """
        cli = self._find_cli()
        if not cli:
            return False

        # Check if the file exists and is executable
        if not os.path.isfile(cli):
            return False

        if not os.access(cli, os.X_OK):
            return False

        # CLI exists and is executable - consider it healthy
        # We don't run --version because some CLIs (like Gemini) have slow startup
        return True

    async def shutdown(self) -> None:
        """No cleanup needed for CLI backend."""
        pass


class InteractiveCLIBackend(CLIBackend):
    """
    Backend for interactive CLI tools that maintain a session.

    This is useful for tools like Codex that can maintain context
    across multiple requests.
    """

    def __init__(self, config: ProviderConfig):
        super().__init__(config)
        self._process: Optional[asyncio.subprocess.Process] = None
        self._lock = asyncio.Lock()

    async def _ensure_process(self) -> asyncio.subprocess.Process:
        """Ensure the interactive process is running."""
        if self._process is None or self._process.returncode is not None:
            cli = self._find_cli()
            if not cli:
                raise ValueError(f"CLI command not found: {self.config.cli_command}")

            cmd = [cli]
            if self.config.cli_args:
                cmd.extend(self.config.cli_args)

            self._process = await asyncio.create_subprocess_exec(
                *cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE,
                stdin=asyncio.subprocess.PIPE,
            )

        return self._process

    async def execute(self, request: GatewayRequest) -> BackendResult:
        """Execute request via interactive CLI session."""
        start_time = time.time()

        async with self._lock:
            try:
                process = await self._ensure_process()

                # Send message to stdin
                message = request.message + "\n"
                process.stdin.write(message.encode("utf-8"))
                await process.stdin.drain()

                # Read response (this is tricky for interactive CLIs)
                # We need to detect when the response is complete
                response_lines = []
                timeout = request.timeout_s or self.config.timeout_s

                try:
                    while True:
                        line = await asyncio.wait_for(
                            process.stdout.readline(),
                            timeout=timeout,
                        )
                        if not line:
                            break

                        decoded = line.decode("utf-8", errors="replace").rstrip()
                        response_lines.append(decoded)

                        # Check for end-of-response markers
                        if self._is_response_complete(decoded):
                            break

                except asyncio.TimeoutError:
                    pass

                latency_ms = (time.time() - start_time) * 1000
                response_text = "\n".join(response_lines)

                return BackendResult.ok(
                    response=self._clean_output(response_text),
                    latency_ms=latency_ms,
                )

            except Exception as e:
                return BackendResult.fail(
                    str(e),
                    latency_ms=(time.time() - start_time) * 1000,
                )

    def _is_response_complete(self, line: str) -> bool:
        """Check if the response is complete based on the line content."""
        # Override in subclasses for specific CLI tools
        # Common patterns: prompt characters, empty lines after content
        return line.endswith("> ") or line.endswith(">>> ")

    async def shutdown(self) -> None:
        """Terminate the interactive process."""
        if self._process and self._process.returncode is None:
            self._process.terminate()
            try:
                await asyncio.wait_for(self._process.wait(), timeout=5.0)
            except asyncio.TimeoutError:
                self._process.kill()
            self._process = None
